{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, CSV, MLJ, VegaLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV to dataframe, select some columns\n",
    "lichen_training = CSV.read(\"C:/Users/julio/Downloads/lichen_training.csv\", DataFrame) |>\n",
    "x -> select(x, \"Total.lichen\", \"basal_area\", \"PL\", \"mean_Long\") |>\n",
    "x -> rename(x, [\"biomass\", \"basalarea\", \"pl\", \"lon\"]) |>\n",
    "x -> coerce(x, Count => Continuous);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lichen_training[!, \"biomass_log\"] = log.(lichen_training[!, :biomass])\n",
    "select!(lichen_training, Not(:biomass));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┬─────────┬────────────┐\n",
       "│\u001b[22m _.names     \u001b[0m│\u001b[22m _.types \u001b[0m│\u001b[22m _.scitypes \u001b[0m│\n",
       "├─────────────┼─────────┼────────────┤\n",
       "│ basalarea   │ Float64 │ Continuous │\n",
       "│ pl          │ Float64 │ Continuous │\n",
       "│ lon         │ Float64 │ Continuous │\n",
       "│ biomass_log │ Float64 │ Continuous │\n",
       "└─────────────┴─────────┴────────────┘\n",
       "_.nrows = 78\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# schema \n",
    "schema(lichen_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictors/responde variable\n",
    "y, X = unpack(lichen_training, ==(:biomass_log), _ -> true; rng=1010);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConstantRegressor                       (MLJModels)\n",
      "DecisionTreeRegressor                   (BetaML)\n",
      "DecisionTreeRegressor                   (DecisionTree)\n",
      "DeterministicConstantRegressor          (MLJModels)\n",
      "ElasticNetRegressor                     (MLJLinearModels)\n",
      "EvoTreeGaussian                         (EvoTrees)\n",
      "EvoTreeRegressor                        (EvoTrees)\n",
      "HuberRegressor                          (MLJLinearModels)\n",
      "KNNRegressor                            (NearestNeighborModels)\n",
      "KPLSRegressor                           (PartialLeastSquaresRegressor)\n",
      "LADRegressor                            (MLJLinearModels)\n",
      "LassoRegressor                          (MLJLinearModels)\n",
      "LinearRegressor                         (GLM)\n",
      "LinearRegressor                         (MLJLinearModels)\n",
      "LinearRegressor                         (MultivariateStats)\n",
      "NeuralNetworkRegressor                  (MLJFlux)\n",
      "PLSRegressor                            (PartialLeastSquaresRegressor)\n",
      "QuantileRegressor                       (MLJLinearModels)\n",
      "RandomForestRegressor                   (BetaML)\n",
      "RandomForestRegressor                   (DecisionTree)\n",
      "RidgeRegressor                          (MLJLinearModels)\n",
      "RidgeRegressor                          (MultivariateStats)\n",
      "RobustRegressor                         (MLJLinearModels)\n"
     ]
    }
   ],
   "source": [
    "# Search for models that match the data scitype and are pure Julia\n",
    "for m in models(matching(X, y))\n",
    "    if m.is_pure_julia == true\n",
    "        println(rpad(m.name, 40), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\julio\\.julia\\packages\\MLJModels\\GKDnU\\src\\loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJLinearModels.RidgeRegressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a RidgeRegressor\n",
    "ridge_regressor = @load RidgeRegressor pkg=MLJLinearModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline276(\n",
       "    standardizer = Standardizer(\n",
       "            features = Symbol[],\n",
       "            ignore = false,\n",
       "            ordered_factor = false,\n",
       "            count = false),\n",
       "    ridge_regressor = RidgeRegressor(\n",
       "            lambda = 1.0,\n",
       "            fit_intercept = true,\n",
       "            penalize_intercept = false,\n",
       "            solver = nothing))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "ridge_regressor_pipe = @pipeline(Standardizer(), ridge_regressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{Pipeline276,…} trained 0 times; caches data\n",
       "  args: \n",
       "    1:\tSource @482 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @217 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an MLJ machine (model + data)\n",
    "rr_model = machine(ridge_regressor_pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([66, 63, 5, 22, 49, 15, 47, 64, 35, 12  …  11, 67, 54, 73, 32, 4, 62, 61, 57, 21], [14, 78, 40, 27, 74, 68, 18, 2, 53, 50  …  77, 29, 69, 7, 60, 59, 17, 30, 43, 51])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split into train/test subsets\n",
    "y, X = unpack(lichen_training, ==(:biomass_log), _ -> true; rng=1010);\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{Pipeline276,…}.\n",
      "└ @ MLJBase C:\\Users\\julio\\.julia\\packages\\MLJBase\\QXObv\\src\\machines.jl:403\n",
      "┌ Info: Training Machine{Standardizer,…}.\n",
      "└ @ MLJBase C:\\Users\\julio\\.julia\\packages\\MLJBase\\QXObv\\src\\machines.jl:403\n",
      "┌ Info: Training Machine{RidgeRegressor,…}.\n",
      "└ @ MLJBase C:\\Users\\julio\\.julia\\packages\\MLJBase\\QXObv\\src\\machines.jl:403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{Pipeline276,…} trained 1 time; caches data\n",
       "  args: \n",
       "    1:\tSource @482 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @217 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the machine\n",
    "fit!(rr_model, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ridge_regressor = (coefs = [:basalarea => -0.7942611119507311, :pl => 1.2122873454925065, :lon => -1.0287575660792603],\n",
       "                    intercept = 4.4364774738687665,),\n",
       " standardizer = Dict(:basalarea => (20.008545454545455, 9.491712255901016), :pl => (61.6, 42.11562567415954), :lon => (-125.2877088, 0.839681844712773)),\n",
       " machines = Machine[Machine{Standardizer,…}, Machine{RidgeRegressor,…}],\n",
       " fitted_params_given_machine = OrderedCollections.LittleDict{Any, Any, Vector{Any}, Vector{Any}}(Machine{Standardizer,…} => Dict(:basalarea => (20.008545454545455, 9.491712255901016), :pl => (61.6, 42.11562567415954), :lon => (-125.2877088, 0.839681844712773)), Machine{RidgeRegressor,…} => (coefs = [:basalarea => -0.7942611119507311, :pl => 1.2122873454925065, :lon => -1.0287575660792603], intercept = 4.4364774738687665)),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check trained parameters\n",
    "fitted_params(rr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_pred = predict(rr_model, rows=test)\n",
    "y_train_pred = predict(rr_model, rows=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LPLoss\", \"LogCoshLoss\", \"Accuracy\", \"BalancedAccuracy\", \"ConfusionMatrix\", \"FScore\", \"FalseDiscoveryRate\", \"FalseNegative\", \"FalseNegativeRate\", \"FalsePositive\", \"FalsePositiveRate\", \"MatthewsCorrelation\", \"MeanAbsoluteError\", \"MeanAbsoluteProportionalError\", \"MisclassificationRate\", \"MulticlassFScore\", \"MulticlassFalseDiscoveryRate\", \"MulticlassFalseNegative\", \"MulticlassFalseNegativeRate\", \"MulticlassFalsePositive\", \"MulticlassFalsePositiveRate\", \"MulticlassNegativePredictiveValue\", \"MulticlassPrecision\", \"MulticlassTrueNegative\", \"MulticlassTrueNegativeRate\", \"MulticlassTruePositive\", \"MulticlassTruePositiveRate\", \"NegativePredictiveValue\", \"Precision\", \"RSquared\", \"RootMeanSquaredError\", \"RootMeanSquaredLogError\", \"RootMeanSquaredLogProportionalError\", \"RootMeanSquaredProportionalError\", \"TrueNegative\", \"TrueNegativeRate\", \"TruePositive\", \"TruePositiveRate\", \"HuberLoss\", \"L1EpsilonInsLoss\", \"L2EpsilonInsLoss\", \"LPDistLoss\", \"LogitDistLoss\", \"PeriodicLoss\", \"QuantileLoss\"]\n"
     ]
    }
   ],
   "source": [
    "# Get list of accuracy measures\n",
    "# [m.name for m in measures() if m.target_scitype <: scitype(y)]\n",
    "println([(m.name) for m in measures() if m.prediction_type == :deterministic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NamedTuple{(:name, :instances, :human_name, :target_scitype, :supports_weights, :supports_class_weights, :prediction_type, :orientation, :reports_each_observation, :aggregation, :is_feature_dependent, :docstring, :distribution_type), Tuple{String, Vector{String}, String, Union, Bool, Bool, Symbol, Symbol, Bool, StatisticalTraits.RootMeanSquare, Bool, String, DataType}}[(name = RootMeanSquaredError, instances = [rms, rmse, root_mean_squared_error], ...)]\n"
     ]
    }
   ],
   "source": [
    "println([(m) for m in measures() if m.name == \"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms(y_test_pred, y[test]) = 2.6312134768852733\n",
      "rms(y_train_pred, y[train]) = 2.2170870123096473\n",
      "rmsp(y_test_pred, y[test]) = 2.728853375593934\n",
      "rmsp(y_train_pred, y[train]) = 2.607014111366455\n"
     ]
    }
   ],
   "source": [
    "# Show some accuracy measures\n",
    "@show rms(y_test_pred, y[test])\n",
    "@show rms(y_train_pred, y[train])\n",
    "@show rmsp(y_test_pred, y[test])\n",
    "@show rmsp(y_train_pred, y[train]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Not retraining Machine{Pipeline276,…}. Use `force=true` to force.\n",
      "└ @ MLJBase C:\\Users\\julio\\.julia\\packages\\MLJBase\\QXObv\\src\\machines.jl:406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{Pipeline276,…} trained 2 times; caches data\n",
       "  args: \n",
       "    1:\tSource @482 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @217 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the machine using the complete training dataset\n",
    "fit!(rr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV to dataframe, select the same columns used for training\n",
    "lichen = CSV.read(\"C:/Users/julio/Downloads/predicted_biomass_Nov2021.csv\", DataFrame) |>\n",
    "x -> select(x, :BASAL_AREA, :PL, :LON) |>\n",
    "x -> rename(x, [\"basalarea\", \"pl\", \"lon\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a new dataset\n",
    "biomass = exp.(predict(rr_model, lichen));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:/Users/julio/Downloads/predicted_biomass_rr.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export results to CSV\n",
    "CSV.write(\"C:/Users/julio/Downloads/predicted_biomass_rr.csv\", DataFrame(biomass=biomass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
